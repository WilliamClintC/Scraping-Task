{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def extract_charts_from_pdf(pdf_path, output_folder):\n",
    "    \"\"\"\n",
    "    Extract only chart regions from PDF using computer vision techniques\n",
    "    with lower detection thresholds to catch more charts\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    print(f\"Total pages: {len(doc)}\")\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        print(f\"Processing page {page_num+1}...\")\n",
    "        \n",
    "        # Render page at high resolution\n",
    "        zoom = 4\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "        \n",
    "        # Convert to numpy array for OpenCV processing\n",
    "        img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "        img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Make a copy for visualization\n",
    "        img_display = img_cv.copy()\n",
    "        \n",
    "        # Convert to grayscale for processing\n",
    "        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply threshold to separate foreground from background\n",
    "        _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        # Process large contours that might be charts\n",
    "        chart_count = 0\n",
    "        # Process more contours with lower thresholds\n",
    "        for i, contour in enumerate(contours[:15]):  # Check the 15 largest contours (increased from 10)\n",
    "            # Get the contour area\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            # Skip if the area is too small or too large - LOWERED THRESHOLD from 5% to 2%\n",
    "            total_area = img_cv.shape[0] * img_cv.shape[1]\n",
    "            if area < (total_area * 0.02) or area > (total_area * 0.95):  # More permissive range\n",
    "                continue\n",
    "            \n",
    "            # Get bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Skip if aspect ratio is extreme - EXPANDED RANGE from 0.2-5 to 0.1-8\n",
    "            aspect_ratio = float(w) / h\n",
    "            if aspect_ratio < 0.1 or aspect_ratio > 8:  # More permissive aspect ratio\n",
    "                continue\n",
    "            \n",
    "            # Skip if region appears to be full of text - LOWERED THRESHOLD from 0.1 to 0.05\n",
    "            roi = binary[y:y+h, x:x+w]\n",
    "            density = np.count_nonzero(roi) / (w * h)\n",
    "            if density < 0.05:  # More permissive density check\n",
    "                continue\n",
    "            \n",
    "            # Cut out the region\n",
    "            chart_region = img_cv[y:y+h, x:x+w]\n",
    "            \n",
    "            # Draw the rectangle on the visualization image\n",
    "            cv2.rectangle(img_display, (x, y), (x+w, y+h), (0, 255, 0), 10)\n",
    "            \n",
    "            # Save the chart region\n",
    "            chart_count += 1\n",
    "            chart_filename = f\"chart_page{page_num+1}_region{chart_count}.png\"\n",
    "            chart_path = os.path.join(output_folder, chart_filename)\n",
    "            cv2.imwrite(chart_path, chart_region)\n",
    "            print(f\"  Saved chart region: {chart_path}\")\n",
    "            \n",
    "            # Save debug info\n",
    "            debug_filename = f\"chart_debug_p{page_num+1}_r{chart_count}.txt\"\n",
    "            debug_path = os.path.join(output_folder, debug_filename)\n",
    "            with open(debug_path, 'w') as f:\n",
    "                f.write(f\"Area: {area} pixels ({area/total_area*100:.2f}% of page)\\n\")\n",
    "                f.write(f\"Dimensions: {w}x{h} pixels\\n\")\n",
    "                f.write(f\"Aspect ratio: {aspect_ratio:.2f}\\n\")\n",
    "                f.write(f\"Content density: {density:.2f}\\n\")\n",
    "        \n",
    "        # Save the visualization with rectangles around detected charts\n",
    "        vis_filename = f\"page{page_num+1}_detection.png\"\n",
    "        vis_path = os.path.join(output_folder, vis_filename)\n",
    "        cv2.imwrite(vis_path, img_display)\n",
    "        print(f\"  Saved detection visualization: {vis_path}\")\n",
    "        \n",
    "        # Also save the binary image to see what's being used for contour detection\n",
    "        bin_filename = f\"page{page_num+1}_binary.png\"\n",
    "        bin_path = os.path.join(output_folder, bin_filename)\n",
    "        cv2.imwrite(bin_path, binary)\n",
    "        print(f\"  Saved binary image: {bin_path}\")\n",
    "        \n",
    "        # If no charts detected using contour method, try an alternative approach\n",
    "        if chart_count == 0:\n",
    "            print(f\"  No charts detected on page {page_num+1} using contour method. Trying alternative...\")\n",
    "            \n",
    "            # Try to identify grid-like structures (common in charts)\n",
    "            # Apply Canny edge detection with lower thresholds\n",
    "            edges = cv2.Canny(gray, 30, 150)  # Lower minimum threshold (50 → 30)\n",
    "            \n",
    "            # Dilate to connect lines\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "            \n",
    "            # Find lines using Hough transform with lower thresholds\n",
    "            lines = cv2.HoughLinesP(dilated, 1, np.pi/180, \n",
    "                                   threshold=80,       # Lower threshold (100 → 80)\n",
    "                                   minLineLength=80,   # Detect shorter lines (100 → 80)\n",
    "                                   maxLineGap=30)      # Allow bigger gaps (20 → 30)\n",
    "            \n",
    "            if lines is not None:\n",
    "                print(f\"  Found {len(lines)} lines\")\n",
    "                \n",
    "                # Draw lines on a separate image\n",
    "                line_img = np.zeros_like(img_cv)\n",
    "                for line in lines:\n",
    "                    x1, y1, x2, y2 = line[0]\n",
    "                    cv2.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Save the line detection image\n",
    "                line_filename = f\"page{page_num+1}_lines.png\"\n",
    "                line_path = os.path.join(output_folder, line_filename)\n",
    "                cv2.imwrite(line_path, line_img)\n",
    "                print(f\"  Saved line detection: {line_path}\")\n",
    "                \n",
    "                # Try to find chart regions using densities of lines\n",
    "                if len(lines) > 5:  # If we found enough lines\n",
    "                    # Detect grid patterns - common in charts\n",
    "                    # (Simplified approach: divide page into sections and check line density)\n",
    "                    sections_h = 3\n",
    "                    sections_v = 3\n",
    "                    height, width = dilated.shape\n",
    "                    \n",
    "                    for section_y in range(sections_v):\n",
    "                        for section_x in range(sections_h):\n",
    "                            # Calculate section coordinates\n",
    "                            x1 = int(section_x * width / sections_h)\n",
    "                            y1 = int(section_y * height / sections_v)\n",
    "                            x2 = int((section_x + 1) * width / sections_h)\n",
    "                            y2 = int((section_y + 1) * height / sections_v)\n",
    "                            \n",
    "                            # Count lines in this section\n",
    "                            section_lines = 0\n",
    "                            for line in lines:\n",
    "                                lx1, ly1, lx2, ly2 = line[0]\n",
    "                                # Check if line is in this section\n",
    "                                if (x1 <= lx1 <= x2 or x1 <= lx2 <= x2) and \\\n",
    "                                   (y1 <= ly1 <= y2 or y1 <= ly2 <= y2):\n",
    "                                    section_lines += 1\n",
    "                            \n",
    "                            # If section has more than 5 lines, it might be a chart\n",
    "                            if section_lines > 5:\n",
    "                                # Save the section\n",
    "                                section = img_cv[y1:y2, x1:x2]\n",
    "                                chart_count += 1\n",
    "                                sect_filename = f\"chart_page{page_num+1}_section{section_y*sections_h+section_x+1}.png\"\n",
    "                                sect_path = os.path.join(output_folder, sect_filename)\n",
    "                                cv2.imwrite(sect_path, section)\n",
    "                                print(f\"  Saved potential chart section: {sect_path}\")\n",
    "                \n",
    "                # If we still haven't found any chart regions\n",
    "                if chart_count == 0:\n",
    "                    # Save whole page as a fallback\n",
    "                    page_filename = f\"page{page_num+1}_whole.png\"\n",
    "                    page_path = os.path.join(output_folder, page_filename)\n",
    "                    cv2.imwrite(page_path, img_cv)\n",
    "                    print(f\"  Saved whole page as fallback: {page_path}\")\n",
    "        \n",
    "    print(f\"Processing complete. Check {output_folder} for extracted charts.\")\n",
    "\n",
    "# Path to PDF file\n",
    "pdf_path = \"C:/Users/clint/Desktop/Scraping Task/pdfs/02_2018.pdf\"\n",
    "\n",
    "# Output folder for charts\n",
    "output_folder = \"C:/Users/clint/Desktop/Scraping Task/extracted_charts\"\n",
    "\n",
    "# Extract charts from PDF\n",
    "extract_charts_from_pdf(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def extract_charts_from_pdf(pdf_path, output_folder):\n",
    "    \"\"\"\n",
    "    Extract only chart regions from PDF using computer vision techniques\n",
    "    with lower detection thresholds to catch more charts.\n",
    "    Only saves the chart images from the main contour detection method.\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    print(f\"Total pages: {len(doc)}\")\n",
    "    \n",
    "    total_charts = 0\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        print(f\"Processing page {page_num+1}...\")\n",
    "        \n",
    "        # Render page at high resolution\n",
    "        zoom = 8  # Increased from 4 to 8 for higher quality\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "        \n",
    "        # Convert to numpy array for OpenCV processing\n",
    "        img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "        img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert to grayscale for processing\n",
    "        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply threshold to separate foreground from background\n",
    "        _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        # Process large contours that might be charts\n",
    "        chart_count = 0\n",
    "        for i, contour in enumerate(contours[:15]):  # Check the 15 largest contours\n",
    "            # Get the contour area\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            # Skip if the area is too small or too large\n",
    "            total_area = img_cv.shape[0] * img_cv.shape[1]\n",
    "            if area < (total_area * 0.02) or area > (total_area * 0.95):\n",
    "                continue\n",
    "            \n",
    "            # Get bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Skip if aspect ratio is extreme\n",
    "            aspect_ratio = float(w) / h\n",
    "            if aspect_ratio < 0.1 or aspect_ratio > 8:\n",
    "                continue\n",
    "            \n",
    "            # Skip if region appears to be full of text\n",
    "            roi = binary[y:y+h, x:x+w]\n",
    "            density = np.count_nonzero(roi) / (w * h)\n",
    "            if density < 0.05:\n",
    "                continue\n",
    "            \n",
    "            # Cut out the region\n",
    "            chart_region = img_cv[y:y+h, x:x+w]\n",
    "            \n",
    "            # Save the chart region\n",
    "            chart_count += 1\n",
    "            total_charts += 1\n",
    "            chart_filename = f\"chart_page{page_num+1}_region{chart_count}.png\"\n",
    "            chart_path = os.path.join(output_folder, chart_filename)\n",
    "            cv2.imwrite(chart_path, chart_region)\n",
    "            print(f\"  Saved chart: {chart_filename}\")\n",
    "        \n",
    "        if chart_count == 0:\n",
    "            print(f\"  No charts detected on page {page_num+1}\")\n",
    "    \n",
    "    print(f\"Processing complete. Extracted {total_charts} charts to {output_folder}\")\n",
    "\n",
    "# Path to PDF file\n",
    "pdf_path = \"C:/Users/clint/Desktop/Scraping Task/pdfs/01_2018.pdf\" \n",
    "# Output folder for charts\n",
    "output_folder = \"C:/Users/clint/Desktop/Scraping Task/extracted_charts\"\n",
    "\n",
    "# Extract charts from PDF\n",
    "extract_charts_from_pdf(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing PDF 1/80: 01_2018.pdf\n",
      "============================================================\n",
      "\n",
      "Skipping page 1 (first page) as requested\n",
      "Processing page 2...\n",
      "REJECTED: Region with dimensions 3152x1839 - No clear chart elements found\n",
      "  (Found 1 horizontal lines, 6 vertical lines)\n",
      "REJECTED: Region with dimensions 3744x501 - Extreme aspect ratio 7.47\n",
      "  No charts detected on page 2\n",
      "Processing page 3...\n",
      "REJECTED: Region with dimensions 3104x1973 - No clear chart elements found\n",
      "  (Found 0 horizontal lines, 0 vertical lines)\n",
      "REJECTED: Region with dimensions 3112x1856 - No clear chart elements found\n",
      "  (Found 0 horizontal lines, 0 vertical lines)\n",
      "REJECTED: Region with dimensions 3744x501 - Extreme aspect ratio 7.47\n",
      "  No charts detected on page 3\n",
      "Processing page 4...\n",
      "REJECTED: Region with dimensions 3024x2046 - No clear chart elements found\n",
      "  (Found 0 horizontal lines, 6 vertical lines)\n",
      "REJECTED: Region with dimensions 3070x1872 - No clear chart elements found\n",
      "  (Found 1 horizontal lines, 8 vertical lines)\n",
      "REJECTED: Region with dimensions 3744x501 - Extreme aspect ratio 7.47\n",
      "  No charts detected on page 4\n",
      "Processing page 5...\n",
      "REJECTED: Region with dimensions 3744x501 - Extreme aspect ratio 7.47\n",
      "  No charts detected on page 5\n",
      "PDF Summary: 01_2018.pdf\n",
      "Charts found and saved: 0\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing PDF 2/80: 01_2019.pdf\n",
      "============================================================\n",
      "\n",
      "Skipping page 1 (first page) as requested\n",
      "Processing page 2...\n",
      "REJECTED: Region with dimensions 4597x479 - Extreme aspect ratio 9.60\n",
      "REJECTED: Region with dimensions 1553x1300 - Similar to known non-chart\n",
      "REJECTED: Region with dimensions 1553x1300 - Similar to known non-chart\n",
      "REJECTED: Region with dimensions 1553x1300 - Dark background (not typical for plot charts)\n",
      "  No charts detected on page 2\n",
      "Processing page 3...\n",
      "ACCEPTED: 01_2019_plot_1_Average_Retail_Selling_Price_3-5_Year-Old_Sleeper_.png\n",
      "Dimensions: 2305x1494, Ratio: 1.54\n",
      "Chart elements: 91 horizontal lines, 8 vertical lines\n",
      "Background brightness: 246.6, saturation: 0.2\n",
      "Title: Average Retail Selling Price: 3-5 Year-Old Sleeper Tractors Adjusted for Mileage\n",
      "--------------------------------------------------\n",
      "ACCEPTED: 01_2019_plot_2_Average_Selling_Price_Benchmark_Sleeper_Tractor_So.png\n",
      "Dimensions: 2304x1453, Ratio: 1.59\n",
      "Chart elements: 133 horizontal lines, 9 vertical lines\n",
      "Background brightness: 246.3, saturation: 0.2\n",
      "Title: Average Selling Price: Benchmark Sleeper Tractor Sold through the Two Largest Nationwide No-Reserve Auction Companies\n",
      "--------------------------------------------------\n",
      "ACCEPTED: 01_2019_plot_3_Volume_of_the_Three_Most_Common_Sleeper_Tractors_4.png\n",
      "Dimensions: 2304x1303, Ratio: 1.77\n",
      "Chart elements: 122 horizontal lines, 42 vertical lines\n",
      "Background brightness: 246.2, saturation: 0.2\n",
      "Title: Volume of the Three Most Common Sleeper Tractors (4-6 Year-Old) Sold through the Two Largest Nationwide No-Reserve Auctions\n",
      "--------------------------------------------------\n",
      "REJECTED: Region with dimensions 4596x479 - Extreme aspect ratio 9.59\n",
      "Processing page 4...\n",
      "ACCEPTED: 01_2019_plot_4_Dec_est.png\n",
      "Dimensions: 2304x1457, Ratio: 1.58\n",
      "Chart elements: 71 horizontal lines, 27 vertical lines\n",
      "Background brightness: 245.9, saturation: 0.2\n",
      "Title: Dec (est.)\n",
      "--------------------------------------------------\n",
      "ACCEPTED: 01_2019_plot_5_Average_Retail_Selling_Price_of_Selected_3-5_Year-.png\n",
      "Dimensions: 2304x1415, Ratio: 1.63\n",
      "Chart elements: 90 horizontal lines, 20 vertical lines\n",
      "Background brightness: 247.0, saturation: 0.2\n",
      "Title: Average Retail Selling Price of Selected 3-5 Year-Old Sleeper Tractors Adjusted for Mileage\n",
      "--------------------------------------------------\n",
      "ACCEPTED: 01_2019_plot_6_Number_of_Trucks_Retailed_per_Dealership_Rooftop.png\n",
      "Dimensions: 2304x1348, Ratio: 1.71\n",
      "Chart elements: 70 horizontal lines, 6 vertical lines\n",
      "Background brightness: 246.5, saturation: 0.3\n",
      "Title: Number of Trucks Retailed per Dealership Rooftop\n",
      "--------------------------------------------------\n",
      "REJECTED: Region with dimensions 4597x479 - Extreme aspect ratio 9.60\n",
      "Processing page 5...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def is_chart_background(img):\n",
    "    \"\"\"\n",
    "    Analyze background color to determine if it's likely a chart.\n",
    "    Charts typically have white/very light backgrounds.\n",
    "    \"\"\"\n",
    "    # Convert to HSV for better color analysis\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Sample the edges of the image (likely background)\n",
    "    top = img_hsv[0:10, :, :]\n",
    "    bottom = img_hsv[-10:, :, :]\n",
    "    left = img_hsv[:, 0:10, :]\n",
    "    right = img_hsv[:, -10:, :]\n",
    "    \n",
    "    # Combine edges\n",
    "    edges = np.vstack([top.reshape(-1, 3), bottom.reshape(-1, 3), \n",
    "                      left.reshape(-1, 3), right.reshape(-1, 3)])\n",
    "    \n",
    "    # Calculate average values\n",
    "    avg_v = np.mean(edges[:, 2])  # V in HSV (brightness)\n",
    "    avg_s = np.mean(edges[:, 1])  # S in HSV (saturation)\n",
    "    \n",
    "    # White/light background: high V (>220), low S (<30)\n",
    "    is_white_bg = avg_v > 220 and avg_s < 30\n",
    "    \n",
    "    # Check for colored backgrounds - charts rarely have colored backgrounds\n",
    "    dominant_hue = np.median(edges[:, 0])\n",
    "    hue_std = np.std(edges[:, 0])\n",
    "    has_colored_bg = avg_s > 50 and hue_std < 20  # Consistent, saturated color\n",
    "    \n",
    "    # Calculate percentage of dark pixels in the border\n",
    "    dark_pixel_percent = np.mean(edges[:, 2] < 100)\n",
    "    is_dark_bg = dark_pixel_percent > 0.6  # More than 60% dark pixels\n",
    "    \n",
    "    result = {\n",
    "        \"is_light_bg\": is_white_bg,\n",
    "        \"is_dark_bg\": is_dark_bg,\n",
    "        \"has_colored_bg\": has_colored_bg,\n",
    "        \"brightness\": avg_v,\n",
    "        \"saturation\": avg_s\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def has_chart_elements(img):\n",
    "    \"\"\"Detect if image has common chart elements like axes, grid lines, etc.\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Edge detection for finding lines\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Use Hough transform to detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "    \n",
    "    if lines is None:\n",
    "        return False, 0, 0\n",
    "    \n",
    "    # Count horizontal and vertical lines (common in charts)\n",
    "    horiz_lines = 0\n",
    "    vert_lines = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "        \n",
    "        # Horizontal lines (within 10 degrees of horizontal)\n",
    "        if angle < 10 or angle > 170:\n",
    "            horiz_lines += 1\n",
    "        # Vertical lines (within 10 degrees of vertical)\n",
    "        elif 80 < angle < 100:\n",
    "            vert_lines += 1\n",
    "    \n",
    "    # Charts typically have several horizontal and vertical lines\n",
    "    has_axis_lines = horiz_lines >= 3 and vert_lines >= 3\n",
    "    \n",
    "    return has_axis_lines, horiz_lines, vert_lines\n",
    "\n",
    "def extract_charts_from_all_pdfs(pdf_dir, output_dir, csv_path):\n",
    "    \"\"\"Extract charts from all PDFs using enhanced detection criteria\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if CSV exists, create with headers if it doesn't\n",
    "    csv_exists = os.path.isfile(csv_path)\n",
    "    \n",
    "    # List all PDF files in the directory\n",
    "    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    # Get current date/time for CSV\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Counter for total processed\n",
    "    total_pdfs_processed = 0\n",
    "    total_charts_saved = 0\n",
    "    \n",
    "    # Open CSV file in append mode - open once for all PDFs\n",
    "    with open(csv_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['date_extracted', 'pdf_filename', 'accepted_images_count']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write header if file is new\n",
    "        if not csv_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        # Process each PDF file\n",
    "        for pdf_file in pdf_files:\n",
    "            pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing PDF {total_pdfs_processed+1}/{len(pdf_files)}: {pdf_file}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "            # Open the PDF\n",
    "            try:\n",
    "                doc = fitz.open(pdf_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening PDF {pdf_file}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Counter for charts in this PDF\n",
    "            pdf_charts_found = 0\n",
    "            \n",
    "            # Skip the first page as in your code\n",
    "            for page_num, page in enumerate(doc):\n",
    "                if page_num == 0:\n",
    "                    print(f\"Skipping page 1 (first page) as requested\")\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"Processing page {page_num+1}...\")\n",
    "                \n",
    "                # Render page at high resolution (zoom 8 as requested)\n",
    "                zoom = 8\n",
    "                mat = fitz.Matrix(zoom, zoom)\n",
    "                pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "                \n",
    "                # Convert to numpy array for OpenCV processing\n",
    "                img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "                img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                # Convert to grayscale for processing\n",
    "                gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Apply threshold to separate foreground from background\n",
    "                _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "                \n",
    "                # Find contours\n",
    "                contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                # Sort contours by area (largest first)\n",
    "                contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "                \n",
    "                # Try to find titles for the charts (similar to your code)\n",
    "                text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "                \n",
    "                # Process large contours that might be charts\n",
    "                chart_count = 0\n",
    "                for i, contour in enumerate(contours[:15]):  # Check the 15 largest contours\n",
    "                    # Get the contour area\n",
    "                    area = cv2.contourArea(contour)\n",
    "                    \n",
    "                    # Skip if the area is too small or too large\n",
    "                    total_area = img_cv.shape[0] * img_cv.shape[1]\n",
    "                    if area < (total_area * 0.02) or area > (total_area * 0.95):\n",
    "                        continue\n",
    "                    \n",
    "                    # Get bounding rectangle\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    \n",
    "                    # Cut out the region for analysis\n",
    "                    chart_region = img_cv[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Check dimensions - avoid extremely wide/tall images\n",
    "                    aspect_ratio = float(w) / h\n",
    "                    \n",
    "                    # STRICTER ASPECT RATIO CHECK - plot charts are typically not extremely wide/tall\n",
    "                    if aspect_ratio < 0.6 or aspect_ratio > 2.0:\n",
    "                        print(f\"REJECTED: Region with dimensions {w}x{h} - Extreme aspect ratio {aspect_ratio:.2f}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # FILTER: Check for unusual dimensions like the specific examples mentioned\n",
    "                    # Check for wide banners (like 4896x663)\n",
    "                    if w > 3000 and h < 800:\n",
    "                        print(f\"REJECTED: Region with dimensions {w}x{h} - Looks like a banner/header\")\n",
    "                        continue\n",
    "                    \n",
    "                    # FILTER: Check if dimensions are close to known non-chart examples\n",
    "                    known_non_charts = [(4896, 663), (1590, 1300), (1103, 938), (1440, 1202)]\n",
    "                    for known_w, known_h in known_non_charts:\n",
    "                        w_sim = abs(w - known_w) / max(w, known_w)\n",
    "                        h_sim = abs(h - known_h) / max(h, known_h)\n",
    "                        if w_sim < 0.1 and h_sim < 0.1:  # Within 10% of known non-chart dimensions\n",
    "                            print(f\"REJECTED: Region with dimensions {w}x{h} - Similar to known non-chart\")\n",
    "                            continue\n",
    "                    \n",
    "                    # FILTER: Background check\n",
    "                    bg_analysis = is_chart_background(chart_region)\n",
    "                    \n",
    "                    # Reject dark or colored backgrounds (unusual for plots)\n",
    "                    if bg_analysis[\"is_dark_bg\"]:\n",
    "                        print(f\"REJECTED: Region with dimensions {w}x{h} - Dark background (not typical for plot charts)\")\n",
    "                        continue\n",
    "                        \n",
    "                    if bg_analysis[\"has_colored_bg\"]:\n",
    "                        print(f\"REJECTED: Region with dimensions {w}x{h} - Colored background (unusual for plot charts)\")\n",
    "                        continue\n",
    "                    \n",
    "                    # FILTER: Check for chart elements (axes, grid lines)\n",
    "                    has_axes, horiz_count, vert_count = has_chart_elements(chart_region)\n",
    "                    if not has_axes:\n",
    "                        print(f\"REJECTED: Region with dimensions {w}x{h} - No clear chart elements found\")\n",
    "                        print(f\"  (Found {horiz_count} horizontal lines, {vert_count} vertical lines)\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if region appears to be full of text (not a chart)\n",
    "                    roi = binary[y:y+h, x:x+w]\n",
    "                    density = np.count_nonzero(roi) / (w * h)\n",
    "                    if density < 0.05 or density > 0.4:  # Too sparse or too dense\n",
    "                        print(f\"REJECTED: Region with dimensions {w}x{h} - Content density ({density:.3f}) not characteristic of charts\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Try to find a title for this chart\n",
    "                    title = \"Unknown_Title\"\n",
    "                    \n",
    "                    # Calculate the chart position in original PDF coordinates (divide by zoom)\n",
    "                    orig_rect = fitz.Rect(\n",
    "                        x / zoom, \n",
    "                        y / zoom, \n",
    "                        (x + w) / zoom, \n",
    "                        (y + h) / zoom\n",
    "                    )\n",
    "                    \n",
    "                    # Look for text blocks that could be titles (above the image)\n",
    "                    search_area = fitz.Rect(\n",
    "                        orig_rect.x0 - 20,      # Left edge, expanded by 20 points\n",
    "                        orig_rect.y0 - 150,     # Top edge, look up to 150 points above\n",
    "                        orig_rect.x1 + 20,      # Right edge, expanded by 20 points\n",
    "                        orig_rect.y0 + 10       # Include a bit below the top of the image\n",
    "                    )\n",
    "                    \n",
    "                    potential_titles = []\n",
    "                    for block in text_blocks:\n",
    "                        if block[\"type\"] == 0:  # Text block\n",
    "                            block_rect = fitz.Rect(block[\"bbox\"])\n",
    "                            \n",
    "                            # Check if text is within the search area\n",
    "                            if search_area.intersects(block_rect):\n",
    "                                # Extract the text\n",
    "                                block_text = \"\"\n",
    "                                for line in block[\"lines\"]:\n",
    "                                    for span in line[\"spans\"]:\n",
    "                                        block_text += span[\"text\"] + \" \"\n",
    "                                \n",
    "                                # Store the potential title along with its distance and vertical position\n",
    "                                potential_titles.append({\n",
    "                                    \"text\": block_text.strip(),\n",
    "                                    \"distance\": abs(orig_rect.y0 - block_rect.y1),  # Distance to chart\n",
    "                                    \"y_pos\": block_rect.y0  # Y position (for sorting from top to bottom)\n",
    "                                })\n",
    "                    \n",
    "                    # Find the best title - short titles close to the chart\n",
    "                    short_titles = [t for t in potential_titles if \n",
    "                                  len(t[\"text\"].split('\\n')) <= 3 and \n",
    "                                  len(t[\"text\"]) <= 200 and\n",
    "                                  t[\"distance\"] <= 100]\n",
    "                    \n",
    "                    if short_titles:\n",
    "                        # Sort by distance (closest first)\n",
    "                        short_titles.sort(key=lambda x: x[\"distance\"])\n",
    "                        title = short_titles[0][\"text\"]\n",
    "                    elif potential_titles:\n",
    "                        # If no good short titles, try all text sorted from top to bottom\n",
    "                        potential_titles.sort(key=lambda x: x[\"y_pos\"])\n",
    "                        title = potential_titles[0][\"text\"]\n",
    "                        \n",
    "                        # If title is too long, truncate it\n",
    "                        if len(title) > 200:\n",
    "                            title = title[:197] + \"...\"\n",
    "                    \n",
    "                    # Clean up the title\n",
    "                    title = re.sub(r'^(Figure|Fig\\.)\\s+\\d+[.:]\\s*', '', title)\n",
    "                    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "                    \n",
    "                    # Clean title for filename use\n",
    "                    clean_title = re.sub(r'[^\\w\\s-]', '', title)\n",
    "                    clean_title = re.sub(r'\\s+', '_', clean_title)\n",
    "                    clean_title = clean_title[:50]  # Limit length for filename\n",
    "                    \n",
    "                    # Save the chart\n",
    "                    chart_count += 1\n",
    "                    pdf_charts_found += 1\n",
    "                    total_charts_saved += 1\n",
    "                    \n",
    "                    # Format the filename following your convention\n",
    "                    if clean_title == \"Unknown_Title\" or not clean_title:\n",
    "                        chart_filename = f\"{pdf_file.split('.')[0]}_plot_{pdf_charts_found}.png\"\n",
    "                    else:\n",
    "                        chart_filename = f\"{pdf_file.split('.')[0]}_plot_{pdf_charts_found}_{clean_title}.png\"\n",
    "                    \n",
    "                    chart_path = os.path.join(output_dir, chart_filename)\n",
    "                    \n",
    "                    # Save the chart\n",
    "                    cv2.imwrite(chart_path, chart_region)\n",
    "                    \n",
    "                    # Print chart info\n",
    "                    print(f\"ACCEPTED: {chart_filename}\")\n",
    "                    print(f\"Dimensions: {w}x{h}, Ratio: {aspect_ratio:.2f}\")\n",
    "                    print(f\"Chart elements: {horiz_count} horizontal lines, {vert_count} vertical lines\")\n",
    "                    print(f\"Background brightness: {bg_analysis['brightness']:.1f}, saturation: {bg_analysis['saturation']:.1f}\")\n",
    "                    print(f\"Title: {title}\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                if chart_count == 0:\n",
    "                    print(f\"  No charts detected on page {page_num+1}\")\n",
    "            \n",
    "            # Write a single CSV entry per PDF\n",
    "            writer.writerow({\n",
    "                'date_extracted': timestamp,\n",
    "                'pdf_filename': pdf_file,\n",
    "                'accepted_images_count': pdf_charts_found\n",
    "            })\n",
    "            \n",
    "            print(f\"PDF Summary: {pdf_file}\")\n",
    "            print(f\"Charts found and saved: {pdf_charts_found}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "            doc.close()\n",
    "            total_pdfs_processed += 1\n",
    "    \n",
    "    print(f\"\\nComplete! Processed {total_pdfs_processed} PDFs\")\n",
    "    print(f\"Total charts saved: {total_charts_saved}\")\n",
    "\n",
    "# Paths\n",
    "pdf_dir = r\"C:\\Users\\clint\\Desktop\\Scraping Task\\pdfs\"\n",
    "output_dir = r\"C:\\Users\\clint\\Desktop\\Scraping Task\\pdfs\\Images\"\n",
    "csv_path = r\"C:\\Users\\clint\\Desktop\\Scraping Task\\pdf_image_data.csv\"\n",
    "\n",
    "# Extract charts from all PDFs and update CSV\n",
    "extract_charts_from_all_pdfs(pdf_dir, output_dir, csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
